{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Code - Use MongoEnv Conda Environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in NASA Mars News Site into Python\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a BeautifulSoup Object\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prettiy the HTML we downloaded\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the Latest News Title from NASA website and save in a variable\n",
    "news_title = soup.find_all('div', class_='content_title')[1].text\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the Latest News Paragraph from NASA website and save in a variable\n",
    "news_p = soup.find_all('div', class_='article_teaser_body')[0].text\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARS Space Images Scraping - Skip per Instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars Facts Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to scrape the table containing Mars facts from the Mars facts webpage (Pandas can be used to scrape table html)\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "facts_table = pd.read_html(facts_url)\n",
    "facts_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert table to a DataFrame, rename column hearders\n",
    "df = facts_table[0]\n",
    "df.columns = ['Interesting Mars Facts', 'Values']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to convert the data to a HTML table string\n",
    "html_table = df.to_html()\n",
    "#Strip unwanted new lines (/n)\n",
    "html_table.replace('\\n', '')\n",
    "#Save table\n",
    "df.to_html('mars_data_table.html')\n",
    "#Print HTML\n",
    "html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "hem_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hem_url)\n",
    "time.sleep(5)\n",
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the main hemisphere links\n",
    "links = browser.find_by_css(\"a.product-item h3\")\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Empty List\n",
    "hemisphere_image_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a for loop to append dictionary\n",
    "for i in range(len(links)):\n",
    "    hemisphere = {}\n",
    "    \n",
    "    # We have to find the elements on each loop to avoid a stale element exception\n",
    "    browser.find_by_css(\"a.product-item h3\")[i].click()\n",
    "    \n",
    "    # Next, we find the Sample image anchor tag and extract the href\n",
    "    sample_elem = browser.links.find_by_text('Sample').first\n",
    "    hemisphere['img_url'] = sample_elem['href']\n",
    "     \n",
    "    # Get Hemisphere title\n",
    "    hemisphere['title'] = browser.find_by_css(\"h2.title\").text\n",
    "    \n",
    "    # Append hemisphere object to list\n",
    "    hemisphere_image_urls.append(hemisphere)\n",
    "    \n",
    "    # Finally, we navigate backwards\n",
    "    browser.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check your dictionary\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with all your scraped information\n",
    "mars_dict={\n",
    "    \"news_title\":news_title,\n",
    "    'news_p':news_p,\n",
    "    \"fact_table\": df,\n",
    "    \"mars_images\":hemisphere_image_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview your dictionary\n",
    "mars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
